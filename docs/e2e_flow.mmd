%% AI Orchestrator Studio - End-to-End Flow (Mermaid)
%% Normalization → Router → Caching → Analytics Path → Validation → Execution → Grounded Answer → Writeback → Observability

flowchart TD
  A[Prompt] --> N[Normalize Input\nClean text, resolve dates/timezone\nFingerprint]
  N --> R[Rule-Based Router\n(no LLM)]
  R -->|Analytics| AN
  R -->|Documents| DOC
  R -->|General Chat| GC

  %% Caching before LLM
  subgraph CACHING[Early Caching]
    CM[Exact Cache\nRedis]
    CS[Semantic Cache\nQdrant/FAISS]
  end
  N --> CACHING
  CACHING --> R

  %% Analytics path
  AN --> DCC[Decide: Simple vs Complex\nCache vs Execution vs Planner]
  DCC --> SC[Semantic Contract\nLoad metrics, dimensions, rules]
  SC --> MS[Metric Selection\nRules + similarity]
  MS --> PL{Complex?}
  PL -->|No| DP[Deterministic Plan]
  PL -->|Yes| PLLM[Planner LLM\n(JSON plan only)]
  DP --> QV
  PLLM --> QV[Query Validation (Hard Gate)\nValidate metrics & dims\nInject filters\nBlock PII\nEnforce limits]
  QV --> TB[Template-Based Query Build\nNo free SQL\nNo hallucinated joins]
  TB --> RC{Result Cached?}
  RC -->|Yes| GRNA[Grounded Answer\nLLM writes explanation\nUses returned data only]
  RC -->|No| EXE[Execute Data Source\nGoverned APIs]
  EXE --> RV[Result Validation (Second Gate)\nEmpty/spikes/anomalies\nRetry once]
  RV --> GRNA
  GRNA --> WB[Cache Writeback\nPlan/result/semantic]

  %% Observability
  subgraph OBS[Observability]
    LAT[Latency breakdown]
    HIT[Cache hit/miss]
    PUSE[Planner usage]
    TOK[LLM tokens]
    SLA[SLA tracking]
  end
  WB --> OBS

  %% Documents & General Chat (grounded)
  DOC --> DPROC[Retrieve + Ground]
  GC --> GPROC[Guardrails + Ground]
  DPROC --> GRNA
  GPROC --> GRNA
